{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pretrained.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR3L-A5xqpKN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "outputId": "2a6b8e32-e1e6-450e-c3e3-fdd3789a318c"
      },
      "source": [
        "# import all the libraries\n",
        "\n",
        "import numpy as np\n",
        "import sklearn.metrics as metrics\n",
        "from keras.applications import densenet\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Flatten,Dropout\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(densenet.DenseNet121(weights='imagenet', include_top=False, input_shape=(32,32,3), pooling='max'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax')) \n",
        "\n",
        "\n",
        "# find summary\n",
        "# model.summary()\n",
        "\n",
        "# splitting traning and testing set\n",
        "\n",
        "(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\n",
        "trainX = trainX.astype('float32')\n",
        "testX = testX.astype('float32')\n",
        "\n",
        "trainX = densenet.preprocess_input(trainX)\n",
        "testX = densenet.preprocess_input(testX)\n",
        "\n",
        "Y_train = np_utils.to_categorical(trainY, 10)\n",
        "Y_test = np_utils.to_categorical(testY, 10)\n",
        "\n",
        "# Using Adam instead of SGD to speed up training\n",
        "optimizer = Adam(lr=1e-3)  \n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(trainX, trainY, batch_size=64, shuffle=True, epochs=20, validation_data=(testX, testY))\n",
        "\n",
        "yPreds = model.predict(testX)\n",
        "yPred = np.argmax(yPreds, axis=1)\n",
        "yTrue = testY\n",
        "\n",
        "# finding accuracy and loss\n",
        "accuracy = metrics.accuracy_score(yTrue, yPred) * 100\n",
        "\n",
        "\n",
        "# print acc and err\n",
        "print(\"Accuracy : \", accuracy)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 151s 3ms/step - loss: 1.6769 - acc: 0.4318 - val_loss: 1.2569 - val_acc: 0.5466\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 110s 2ms/step - loss: 1.0918 - acc: 0.6230 - val_loss: 1.6086 - val_acc: 0.4784\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 115s 2ms/step - loss: 0.8697 - acc: 0.7103 - val_loss: 0.8916 - val_acc: 0.7267\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 112s 2ms/step - loss: 0.7845 - acc: 0.7388 - val_loss: 1.1228 - val_acc: 0.6340\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 112s 2ms/step - loss: 0.7103 - acc: 0.7685 - val_loss: 0.6684 - val_acc: 0.7761\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.9129 - acc: 0.6925 - val_loss: 1.2809 - val_acc: 0.5516\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.9100 - acc: 0.6894 - val_loss: 0.8127 - val_acc: 0.7189\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 1.1012 - acc: 0.6181 - val_loss: 0.8371 - val_acc: 0.7100\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 110s 2ms/step - loss: 0.9689 - acc: 0.6717 - val_loss: 1.2505 - val_acc: 0.5626\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 1.2346 - acc: 0.5706 - val_loss: 0.9842 - val_acc: 0.6515\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.8846 - acc: 0.6956 - val_loss: 0.7721 - val_acc: 0.7491\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 112s 2ms/step - loss: 0.7033 - acc: 0.7605 - val_loss: 0.6787 - val_acc: 0.7682\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 112s 2ms/step - loss: 0.7643 - acc: 0.7508 - val_loss: 1.3642 - val_acc: 0.5902\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 112s 2ms/step - loss: 0.8628 - acc: 0.7112 - val_loss: 0.6947 - val_acc: 0.7616\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.6903 - acc: 0.7709 - val_loss: 2.5728 - val_acc: 0.6007\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 110s 2ms/step - loss: 0.5931 - acc: 0.8069 - val_loss: 0.7468 - val_acc: 0.7779\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.7122 - acc: 0.7625 - val_loss: 0.9282 - val_acc: 0.6835\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 110s 2ms/step - loss: 1.1249 - acc: 0.6083 - val_loss: 0.9491 - val_acc: 0.6668\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.8309 - acc: 0.7123 - val_loss: 0.7319 - val_acc: 0.7488\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.6695 - acc: 0.7681 - val_loss: 0.6941 - val_acc: 0.7668\n",
            "[[5.15507185e-04 3.99391341e-04 1.36083446e-03 ... 1.70816260e-03\n",
            "  3.80481797e-04 1.45422455e-04]\n",
            " [8.28323420e-03 4.52900589e-01 1.11550820e-04 ... 2.29960719e-07\n",
            "  5.36131024e-01 2.27554794e-03]\n",
            " [1.17249526e-01 4.53777313e-02 5.44142351e-03 ... 4.02089022e-03\n",
            "  7.57536829e-01 3.36359031e-02]\n",
            " ...\n",
            " [8.07451142e-05 1.24493340e-06 7.72864511e-03 ... 1.81439565e-03\n",
            "  5.36091966e-06 2.25457325e-06]\n",
            " [4.50047433e-01 3.39364380e-01 8.35360587e-02 ... 1.28382705e-02\n",
            "  5.71966497e-03 6.97272783e-03]\n",
            " [1.26712689e-06 1.46664347e-09 9.08741549e-06 ... 9.87611592e-01\n",
            "  4.87104523e-10 4.50696156e-08]]\n",
            "Accuracy :  76.68\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}