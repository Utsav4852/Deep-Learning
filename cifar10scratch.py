# -*- coding: utf-8 -*-
"""cifar10densenet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iL9AEEJZq59yM-07u6NaHQD6omecQFuy
"""

# import all the libraries

import numpy as np
import sklearn.metrics as metrics
from keras.applications import densenet
from keras.datasets import cifar10
from keras.utils import np_utils
from keras.optimizers import Adam

# create the model from keras and set weights==none for the traung it from the scratch
model = densenet.DenseNet121(weights=None, input_shape=(32,32,3), pooling=None, classes=10)

# find summary
model.summary()

# Splitting traning and testing set
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Converting to float
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

# converting data into normalize form
x_train = densenet.preprocess_input(x_train)
x_test = densenet.preprocess_input(x_test)

# one-hot encoding
Y_train = np_utils.to_categorical(y_train, 10)
Y_test = np_utils.to_categorical(y_test, 10)

# Using Adam instead of SGD to speed up training and set learning rate 0.001
optimizer = Adam(lr=1e-3)  

# compile the model
model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=["accuracy"])

# train the model
model.fit(x_train, y_train, batch_size=64, shuffle=y_true, epochs=20, validation_data=(x_test, y_test))

Preds = model.predict(x_test)
y_Pred = np.argmax(Preds, axis=1)
y_true = y_test

# finding accuracy and loss
accuracy = metrics.accuracy_score(y_true, y_Pred) * 100

# print testing accuracy
print("Accuracy : ", accuracy)